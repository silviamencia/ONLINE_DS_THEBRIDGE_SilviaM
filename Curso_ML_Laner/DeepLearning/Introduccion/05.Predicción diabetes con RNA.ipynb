{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcc40f5-1d27-423f-ac0a-07c448de8d5b",
   "metadata": {},
   "source": [
    "# Problema clasificación con RNA y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a0f673-5f7f-4aeb-95ad-a615b0382183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee52bb9-f52f-44a5-8008-1df871f4fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6a7788-2b7d-4ee2-963b-ce247d7467f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el conjunto de datos\n",
    "os.chdir (os.getcwd())\n",
    "df = pd.read_csv(r\"datos/diabetes.csv\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9513123c-11ec-41e1-9b0f-65427d59e6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       768 non-null    int64  \n",
      " 1   1       768 non-null    int64  \n",
      " 2   2       768 non-null    int64  \n",
      " 3   3       768 non-null    int64  \n",
      " 4   4       768 non-null    int64  \n",
      " 5   5       768 non-null    float64\n",
      " 6   6       768 non-null    float64\n",
      " 7   7       768 non-null    int64  \n",
      " 8   8       768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72dc4f4a-d75a-4e88-86c7-852c0aff82d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d3b2a-2f15-4642-9368-041efb584fbb",
   "metadata": {},
   "source": [
    "Significado de las columnas:\n",
    "\n",
    " 0. Number of times pregnant\n",
    " 1. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    " 2. Diastolic blood pressure (mm Hg)\n",
    " 3. Triceps skin fold thickness (mm)\n",
    " 4. 2-Hour serum insulin (mu U/ml)\n",
    " 5. Body mass index (weight in kg/(height in m)^2)\n",
    " 6. Diabetes pedigree function\n",
    " 7. Age (years)\n",
    " 8. Variable clase (Tiene diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01202bc-e23a-4793-abc8-22750828e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en X e y\n",
    "X = df.iloc[:,0:8]\n",
    "y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899ed651-0505-456b-b799-17d71adb021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee718e19-2a9f-4855-a225-7d5245d31438",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Definimos el modelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09adeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener todos el mismo resultado debemos añadir una semilla\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a42e55b-9cdb-49a7-a0bf-81820d72a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiremos el modelo como una secuencia de capas.\n",
    "# Usaremos el modelo secuencial de manera que podamos ir añadiendo capas hasta estar contentos con la arquitectura desarrollada.\n",
    "model = Sequential()\n",
    "\n",
    "# Partimos de un sistema con 8 variables por lo que nuestra primera capa acomodará dichas variables\n",
    "# En la primera capa oculta usaremos 12 neuronas y una función de activación ReLU\n",
    "# En la segunda capa oculta usaremos 8 neuronas y una función de activación ReLU\n",
    "# Finalmente en la de salida una neurona y función de activación sigmoide\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Nota: Fíjate que el total de neuronas de entrada, lo definimos en la primera capa con input_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746d633-caac-4fb0-a865-f66b75004816",
   "metadata": {},
   "source": [
    "### Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0222457-544f-4e2f-ae99-427bfc9cb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La compilación usa (internamente) librerías numéricas muy eficientes como TensorFlow además de comprobar si tenemos GPU \n",
    "# o sólo CPU\n",
    "# Es necesario definir la función de pérdida que vamos a minimizar (optimizar).  Para este caso minimizaremos \n",
    "# Binary Cross Entropy puesto que funciona bien para problemas binarios de clasificación.\n",
    "# Como métrica (al ser clasificación) usaremos la precisión.\n",
    "# Como optimizador, usaremos el algoritmo \"adam\" ya que ofrece buenos resultados en un amplio abanico de problemas y \n",
    "# además de manera rápida\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              #loss=\"binary_crossentropy\",\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False, # usar cuando valores de predicción sean [0,1]\n",
    "                                                      label_smoothing=0.0,\n",
    "                                                      axis=-1,\n",
    "                                                      reduction=\"auto\",\n",
    "                                                      name=\"binary_crossentropy\"),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1d83b-31e7-40bc-8a7d-d79dedefa38e",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c037df80-32c5-45ed-b4bd-e2d7b42c734e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.7432 - accuracy: 0.5829\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.5885\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8385 - accuracy: 0.6406\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7893 - accuracy: 0.6704\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7885 - accuracy: 0.6741\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6778\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.6685\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.6648\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.6797\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6797\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.6648\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.6778\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6890\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.6946\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6927\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6909\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6760\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6983\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6890\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7095\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6890\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6983\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6909\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6927\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6927\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.7039\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.6983\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6927\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6946\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.7002\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6872\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6965\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.7058\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.7076\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.7058\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.7132\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.7039\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.7058\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.7244\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.7207\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7207\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.7430\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.7132\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7393\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7337\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.7281\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.7374\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7449\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.7114\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7318\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7207\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7263\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.7132\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7318\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7467\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7300\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7356\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7505\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7188\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 962us/step - loss: 0.5462 - accuracy: 0.7318\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7169\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7374\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7486\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7374\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7374\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7430\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7337\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7374\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7598\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7318\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.7244\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7430\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7207\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7263\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.7300\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7281\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7244\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7393\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7486\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7561\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7374\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7095\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7225\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7393\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7467\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 962us/step - loss: 0.5238 - accuracy: 0.7449\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7542\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7523\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.7263\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7412\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7263\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7486\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7412\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7412\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7523\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7244\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7467\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7356\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7281\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7430\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7318\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.7281\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7244\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7467\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7337\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5315 - accuracy: 0.7430\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7561\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7449\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7300\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7393\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7505\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7337\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7542\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7449\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7486\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7467\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7412\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7635\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7449\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7337\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7393\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7412\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7523\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7486\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7467\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7356\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7523\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7579\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7356\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7449\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7542\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7449\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7356\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7412\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7467\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7486\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7616\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7672\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7672\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7523\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.7263\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7281\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7430\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7561\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7449\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7579\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7561\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7430\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6284c0c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed(1)\n",
    "# random.set_seed(1)\n",
    "# El argumento batch_size, nos permite definir el número de filas que se considerarán, antes de que los pesos del\n",
    "# modelo se reajusten dentro de cada ciclo.\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# En el aprendizaje automático, entrenar modelos de aprendizaje profundo con grandes conjuntos de datos puede \n",
    "# requerir mucha memoria y recursos computacionales. El uso de un tamaño de lote adecuado puede ayudar a evitar \n",
    "# problemas de memoria y a mejorar la velocidad de entrenamiento.\n",
    "\n",
    "# Por ejemplo, si tenemos un conjunto de datos de 1000 muestras y establecemos batch_size=10, esto significa \n",
    "# que se utilizarán 10 muestras a la vez para actualizar los pesos del modelo en cada iteración del entrenamiento. \n",
    "# Por lo tanto, el proceso de entrenamiento se dividirá en 100 iteraciones, una para cada lote de 10 muestras.\n",
    "\n",
    "# El tamaño de lote adecuado depende del conjunto de datos y del modelo. En general, un tamaño de lote más grande\n",
    "# puede proporcionar un mejor rendimiento de entrenamiento, pero requiere más memoria. Por otro lado, un tamaño de\n",
    "# lote más pequeño puede proporcionar una mejor generalización del modelo, pero puede requerir más iteraciones para\n",
    "# converger a una solución óptima.\n",
    "\n",
    "# En resumen, batch_size es un parámetro importante en el proceso de entrenamiento de modelos de aprendizaje profundo en Keras y su elección puede afectar el rendimiento del modelo y la velocidad de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff0822-25fe-4bd9-8591-d9eb67ee0f3a",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594870e3-0d4c-42a9-95e3-129dfdc5e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7654\n",
      "Accuracy: 76.54\n"
     ]
    }
   ],
   "source": [
    "# Con la red neuronal entrenada, ahora debemos evaluar cómo ha funcionado.\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6305f141-d464-49e3-bd37-06feb1eef7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No es un mal resultado, tenemos una precisión de más del 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c8cb0-afee-4f5d-85d4-42bcbf39141e",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e54af8-55eb-4da4-abf8-c6699c07d86c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = model.predict(X_test)\n",
    "\n",
    "# La función sigmoide nos devueve los resultados en formato probabilidad.\n",
    "# Convertimos los mismos a casos, tomando como umbral 0.5\n",
    "y_pred = (predicciones > 0.5).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8eb3b21-b518-47d0-babf-af7acdc5ad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117,  26],\n",
       "       [ 40,  48]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf0de0-b6cb-437c-a92c-1b992e1d533b",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf349a-48f3-46a2-85ab-abc2769e600a",
   "metadata": {},
   "source": [
    "1.Configura la red neuronal para que trabaje con 3 capas. \n",
    "- La primera con 15 neuronas y función de activación sigmoide. \n",
    "- La segunda con 10 neuronas y función de activación sigmoide.\n",
    "- La tercera con 8 neuronas y función de activación ReLU.\n",
    "- Una capa de salida con 1 neurona y función de activación sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b692f1a-92cb-4134-b817-ba9cdd99d632",
   "metadata": {},
   "source": [
    "2.Configura la red neuronal para que trabaje con las 3 mismas capas del ejemplo inicial, pero esta vez usa como función de activación de la capa de salida 'softmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f5724-f5db-42f5-95f8-a6bfecb51365",
   "metadata": {},
   "source": [
    "3.En compile, cambia la configuración del optimizer, de manera que en vez de Adam, usemos esta vez SGD:\n",
    "optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.1, nesterov=False, name='SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea0994",
   "metadata": {},
   "source": [
    "3.1.Cambia ahora la función de activación de la capa de salida a sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc7577-0b0d-4c1a-886f-be3c305035be",
   "metadata": {},
   "source": [
    "4.En compile, cambia la configuración del loss para usar como función de pérdida CategoricalCrossentropy.\n",
    "\n",
    "tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction=\"auto\",\n",
    "    name=\"categorical_crossentropy\"),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f2919-396b-484d-b5ad-cfd8b473664c",
   "metadata": {},
   "source": [
    "5.Prueba diferentes configuraciones a ver si consigues mejorar el resultado inicial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
