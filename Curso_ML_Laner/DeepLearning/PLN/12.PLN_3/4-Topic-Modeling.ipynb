{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra técnica para el análisis de textos, es el **Topic Modeling**. El objetivo del Top Modeling es encontrar los 'temas' presentes en el corpus.  Se puede utilizar en buscadores, automatización de atención al cliente, ...\n",
    "\n",
    "Cada documento en el corpus estará formado por al menos un tema.  En este notebook, realizaremos el top modeling a través de **Latent Dirichlet Allocation (LDA)**.\n",
    "El LDA es un aprendizaje no supervisado a través de una nube de palabras.  A través de él podemos encontrar, temas ocultos y clasificar los documentos en base a los temas obtenidos entre otros.\n",
    "\n",
    "https://es.wikipedia.org/wiki/Latent_Dirichlet_Allocation  \n",
    "https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2\n",
    "\n",
    "Para realizar un top modeling, necesitamos:\n",
    "* Document Term Matrix (corpus)\n",
    "* Los términos (topics) que queremos usar.\n",
    "\n",
    "Una vez aplicada el top modeling, es necesario interpretar los resultados para ver si tienen sentido. En el caso de que no lo tengan, se pueden variar el número de temas, los términos en el document-term matrix, los parámetros del modelo o incluso probar un modelo diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic Modeling - Prueba #1 (Todo el texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los módulos LDA con gensim\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>...</th>\n",
       "      <th>zee</th>\n",
       "      <th>zen</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 7484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaah  aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aaah  aah  abc  \\\n",
       "ali           0             0                 0          0     0    0    1   \n",
       "anthony       0             0                 0          0     0    0    0   \n",
       "bill          1             0                 0          0     0    0    0   \n",
       "bo            0             1                 1          1     0    0    0   \n",
       "dave          0             0                 0          0     1    0    0   \n",
       "hasan         0             0                 0          0     0    0    0   \n",
       "jim           0             0                 0          0     0    0    0   \n",
       "joe           0             0                 0          0     0    0    0   \n",
       "john          0             0                 0          0     0    0    0   \n",
       "louis         0             0                 0          0     0    3    0   \n",
       "mike          0             0                 0          0     0    0    0   \n",
       "ricky         0             0                 0          0     0    0    0   \n",
       "\n",
       "         abcs  ability  abject  ...  zee  zen  zeppelin  zero  zillion  \\\n",
       "ali         0        0       0  ...    0    0         0     0        0   \n",
       "anthony     0        0       0  ...    0    0         0     0        0   \n",
       "bill        1        0       0  ...    0    0         0     1        1   \n",
       "bo          0        1       0  ...    0    0         0     1        0   \n",
       "dave        0        0       0  ...    0    0         0     0        0   \n",
       "hasan       0        0       0  ...    2    1         0     1        0   \n",
       "jim         0        0       0  ...    0    0         0     0        0   \n",
       "joe         0        0       0  ...    0    0         0     0        0   \n",
       "john        0        0       0  ...    0    0         0     0        0   \n",
       "louis       0        0       0  ...    0    0         0     2        0   \n",
       "mike        0        0       0  ...    0    0         2     1        0   \n",
       "ricky       0        1       1  ...    0    0         0     0        0   \n",
       "\n",
       "         zombie  zombies  zoning  zoo  éclair  \n",
       "ali           1        0       0    0       0  \n",
       "anthony       0        0       0    0       0  \n",
       "bill          1        1       1    0       0  \n",
       "bo            0        0       0    0       0  \n",
       "dave          0        0       0    0       0  \n",
       "hasan         0        0       0    0       0  \n",
       "jim           0        0       0    0       0  \n",
       "joe           0        0       0    0       0  \n",
       "john          0        0       0    0       1  \n",
       "louis         0        0       0    0       0  \n",
       "mike          0        0       0    0       0  \n",
       "ricky         0        0       0    1       0  \n",
       "\n",
       "[12 rows x 7484 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el document-term matrix generado previamente\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\borja\\OneDrive\\Documents\\C2B\\Bootcamp\\Módulo 8\\Módulo 8\\scripts\\15.PLN\")\n",
    "datos = pd.read_pickle('dtm_stop.pkl')\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ali</th>\n",
       "      <th>anthony</th>\n",
       "      <th>bill</th>\n",
       "      <th>bo</th>\n",
       "      <th>dave</th>\n",
       "      <th>hasan</th>\n",
       "      <th>jim</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>louis</th>\n",
       "      <th>mike</th>\n",
       "      <th>ricky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ali  anthony  bill  bo  dave  hasan  jim  joe  john  louis  \\\n",
       "aaaaah              0        0     1   0     0      0    0    0     0      0   \n",
       "aaaaahhhhhhh        0        0     0   1     0      0    0    0     0      0   \n",
       "aaaaauuugghhhhhh    0        0     0   1     0      0    0    0     0      0   \n",
       "aaaahhhhh           0        0     0   1     0      0    0    0     0      0   \n",
       "aaah                0        0     0   0     1      0    0    0     0      0   \n",
       "\n",
       "                  mike  ricky  \n",
       "aaaaah               0      0  \n",
       "aaaaahhhhhhh         0      0  \n",
       "aaaaauuugghhhhhh     0      0  \n",
       "aaaahhhhh            0      0  \n",
       "aaah                 0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uno de los requerimientos para el LDA es un term-document matrix transpuesto\n",
    "tdm = datos.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el formato de la matriz a 'gensim'\n",
    "# Pasos necesarios df --> matriz dispersa --> corpus gensim\n",
    "matriz_dispersa = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(matriz_dispersa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim necesita de un diccionario con todos los términos y su ubicación en el corpus.\n",
    "# Recuperamos la matriz generada en el script 2\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3687: 'ladies',\n",
       " 2752: 'gentlemen',\n",
       " 7263: 'welcome',\n",
       " 6283: 'stage',\n",
       " 157: 'ali',\n",
       " 7370: 'wong',\n",
       " 3099: 'hi',\n",
       " 3078: 'hello',\n",
       " 6672: 'thank',\n",
       " 1355: 'coming',\n",
       " 2822: 'gonna',\n",
       " 5921: 'shit',\n",
       " 1042: 'cause',\n",
       " 4804: 'pee',\n",
       " 3826: 'like',\n",
       " 4209: 'minutes',\n",
       " 2272: 'everybody',\n",
       " 6988: 'um',\n",
       " 2296: 'exciting',\n",
       " 1707: 'day',\n",
       " 7437: 'year',\n",
       " 6938: 'turned',\n",
       " 7446: 'yes',\n",
       " 4826: 'people',\n",
       " 283: 'appreciate',\n",
       " 6984: 'uh',\n",
       " 6628: 'tell',\n",
       " 3290: 'im',\n",
       " 2766: 'getting',\n",
       " 4573: 'older',\n",
       " 2782: 'girl',\n",
       " 412: 'automatic',\n",
       " 6708: 'thought',\n",
       " 2666: 'fuck',\n",
       " 1969: 'dont',\n",
       " 3665: 'know',\n",
       " 6386: 'straight',\n",
       " 3496: 'jealous',\n",
       " 2598: 'foremost',\n",
       " 4154: 'metabolism',\n",
       " 2785: 'girls',\n",
       " 3581: 'just',\n",
       " 2103: 'eat',\n",
       " 6032: 'sixpack',\n",
       " 5539: 'right',\n",
       " 2835: 'got',\n",
       " 6677: 'thatthat',\n",
       " 551: 'beautiful',\n",
       " 3369: 'inner',\n",
       " 6695: 'thigh',\n",
       " 1245: 'clearance',\n",
       " 2430: 'feet',\n",
       " 6689: 'theres',\n",
       " 3231: 'huge',\n",
       " 2709: 'gap',\n",
       " 3822: 'light',\n",
       " 5041: 'potential',\n",
       " 5270: 'radiating',\n",
       " 6725: 'throughand',\n",
       " 6066: 'sleep',\n",
       " 3382: 'insomnia',\n",
       " 195: 'ambien',\n",
       " 1993: 'download',\n",
       " 4110: 'meditation',\n",
       " 4527: 'oasis',\n",
       " 4968: 'podcast',\n",
       " 949: 'calm',\n",
       " 1120: 'chatter',\n",
       " 5403: 'regret',\n",
       " 5470: 'resentment',\n",
       " 2381: 'family',\n",
       " 1295: 'cluttering',\n",
       " 4191: 'mind',\n",
       " 3856: 'lives',\n",
       " 122: 'ahead',\n",
       " 3226: 'hpv',\n",
       " 4792: 'peace',\n",
       " 4461: 'night',\n",
       " 4570: 'ok',\n",
       " 1339: 'come',\n",
       " 7464: 'youre',\n",
       " 2672: 'fucking',\n",
       " 3902: 'loser',\n",
       " 6676: 'thats',\n",
       " 5717: 'says',\n",
       " 3907: 'lot',\n",
       " 4134: 'men',\n",
       " 7012: 'undetectable',\n",
       " 5338: 'really',\n",
       " 2667: 'fucked',\n",
       " 2769: 'ghost',\n",
       " 3377: 'inside',\n",
       " 4136: 'mens',\n",
       " 722: 'bodies',\n",
       " 735: 'boo',\n",
       " 7364: 'womens',\n",
       " 1945: 'doctor',\n",
       " 6782: 'told',\n",
       " 6388: 'strains',\n",
       " 3637: 'kind',\n",
       " 6937: 'turn',\n",
       " 1071: 'cervical',\n",
       " 966: 'cancer',\n",
       " 723: 'body',\n",
       " 3047: 'heal',\n",
       " 3084: 'helpful',\n",
       " 518: 'basically',\n",
       " 1852: 'die',\n",
       " 5072: 'presence',\n",
       " 7359: 'wolverine',\n",
       " 655: 'bitches',\n",
       " 3640: 'kindle',\n",
       " 6939: 'turning',\n",
       " 5822: 'selfhelp',\n",
       " 3808: 'library',\n",
       " 3407: 'interested',\n",
       " 740: 'books',\n",
       " 5878: 'shades',\n",
       " 2890: 'grey',\n",
       " 3816: 'lifechanging',\n",
       " 3967: 'magic',\n",
       " 6740: 'tidying',\n",
       " 1742: 'declutter',\n",
       " 3156: 'home',\n",
       " 42: 'achieve',\n",
       " 4622: 'optimum',\n",
       " 3792: 'level',\n",
       " 6460: 'success',\n",
       " 3196: 'horrible',\n",
       " 4843: 'person',\n",
       " 3001: 'happy',\n",
       " 3082: 'help',\n",
       " 6796: 'tony',\n",
       " 5563: 'robbins',\n",
       " 4117: 'mei',\n",
       " 3140: 'hoarding',\n",
       " 5114: 'problem',\n",
       " 3187: 'hoping',\n",
       " 1059: 'center',\n",
       " 5115: 'problems',\n",
       " 2815: 'goes',\n",
       " 429: 'away',\n",
       " 1888: 'disappear',\n",
       " 4259: 'mom',\n",
       " 7392: 'world',\n",
       " 1524: 'country',\n",
       " 6600: 'taught',\n",
       " 6726: 'throw',\n",
       " 1847: 'dictators',\n",
       " 4672: 'overtake',\n",
       " 6126: 'snatch',\n",
       " 7234: 'wealth',\n",
       " 602: 'better',\n",
       " 3143: 'hold',\n",
       " 5493: 'retainer',\n",
       " 2849: 'grade',\n",
       " 2983: 'handy',\n",
       " 5957: 'shovel',\n",
       " 913: 'busy',\n",
       " 6443: 'stuffing',\n",
       " 2817: 'gold',\n",
       " 915: 'butt',\n",
       " 5636: 'running',\n",
       " 1370: 'communiststhe',\n",
       " 6750: 'time',\n",
       " 5674: 'san',\n",
       " 2627: 'francisco',\n",
       " 6920: 'trying',\n",
       " 5528: 'rid',\n",
       " 7400: 'worst',\n",
       " 2325: 'experience',\n",
       " 3815: 'life',\n",
       " 2184: 'emotional',\n",
       " 5760: 'screaming',\n",
       " 2466: 'fighting',\n",
       " 7442: 'yelling',\n",
       " 954: 'came',\n",
       " 1256: 'climax',\n",
       " 5394: 'refused',\n",
       " 3786: 'let',\n",
       " 6667: 'texas',\n",
       " 3396: 'instruments',\n",
       " 4014: 'manual',\n",
       " 940: 'calculator',\n",
       " 5113: 'probably',\n",
       " 486: 'bamboozled',\n",
       " 2739: 'generation',\n",
       " 5464: 'required',\n",
       " 922: 'buy',\n",
       " 1510: 'cost',\n",
       " 3564: 'judy',\n",
       " 3520: 'jetsons',\n",
       " 3708: 'laptop',\n",
       " 2695: 'future',\n",
       " 2873: 'graph',\n",
       " 6653: 'tesla',\n",
       " 4413: 'need',\n",
       " 1240: 'clean',\n",
       " 5120: 'procrastinator',\n",
       " 258: 'anymore',\n",
       " 36: 'according',\n",
       " 1747: 'deepakoprah',\n",
       " 7230: 'way',\n",
       " 2889: 'grew',\n",
       " 4766: 'past',\n",
       " 4035: 'married',\n",
       " 7435: 'yeah',\n",
       " 3994: 'man',\n",
       " 3931: 'lucky',\n",
       " 2930: 'guy',\n",
       " 2726: 'gave',\n",
       " 2601: 'forever',\n",
       " 1694: 'dated',\n",
       " 3903: 'losers',\n",
       " 3908: 'lots',\n",
       " 6038: 'skaters',\n",
       " 7197: 'wanna',\n",
       " 2905: 'grownass',\n",
       " 7360: 'woman',\n",
       " 6375: 'stop',\n",
       " 1697: 'dating',\n",
       " 7027: 'unless',\n",
       " 7182: 'wake',\n",
       " 4075: 'mattress',\n",
       " 3650: 'kitchen',\n",
       " 6693: 'theyre',\n",
       " 5874: 'sexy',\n",
       " 4656: 'outside',\n",
       " 3991: 'malt',\n",
       " 3842: 'liquor',\n",
       " 3254: 'husband',\n",
       " 4153: 'met',\n",
       " 7246: 'wedding',\n",
       " 3095: 'hes',\n",
       " 3891: 'looking',\n",
       " 3750: 'league',\n",
       " 5710: 'saw',\n",
       " 4565: 'oh',\n",
       " 2810: 'god',\n",
       " 6697: 'thing',\n",
       " 3755: 'learned',\n",
       " 388: 'attending',\n",
       " 3017: 'harvard',\n",
       " 910: 'business',\n",
       " 5735: 'school',\n",
       " 6860: 'trap',\n",
       " 347: 'ass',\n",
       " 2816: 'going',\n",
       " 6861: 'trapped',\n",
       " 3365: 'initially',\n",
       " 3649: 'kissing',\n",
       " 2460: 'fifth',\n",
       " 1693: 'date',\n",
       " 7042: 'unusual',\n",
       " 1850: 'did',\n",
       " 5204: 'purpose',\n",
       " 3659: 'knew',\n",
       " 1029: 'catch',\n",
       " 2838: 'gotta',\n",
       " 3983: 'make',\n",
       " 2059: 'dude',\n",
       " 576: 'believe',\n",
       " 5791: 'secret',\n",
       " 2712: 'garden',\n",
       " 5179: 'public',\n",
       " 4735: 'park',\n",
       " 3207: 'hosted',\n",
       " 5399: 'reggae',\n",
       " 2447: 'fests',\n",
       " 33: 'accidentally',\n",
       " 3158: 'homeless',\n",
       " 3126: 'hipsters',\n",
       " 6380: 'store',\n",
       " 7058: 'urban',\n",
       " 4651: 'outfitters',\n",
       " 6698: 'things',\n",
       " 1426: 'confusing',\n",
       " 3125: 'hipster',\n",
       " 542: 'beard',\n",
       " 2400: 'fashion',\n",
       " 7206: 'warmth',\n",
       " 2994: 'happened',\n",
       " 3859: 'living',\n",
       " 832: 'broad',\n",
       " 1709: 'daylight',\n",
       " 1144: 'chemistry',\n",
       " 3097: 'hey',\n",
       " 7218: 'wassup',\n",
       " 7162: 'volvo',\n",
       " 2037: 'drop',\n",
       " 2038: 'dropped',\n",
       " 2818: 'golden',\n",
       " 2722: 'gate',\n",
       " 7222: 'watched',\n",
       " 5633: 'run',\n",
       " 4174: 'middle',\n",
       " 2653: 'friends',\n",
       " 336: 'asian',\n",
       " 5931: 'shocked',\n",
       " 7073: 'usually',\n",
       " 337: 'asianamerican',\n",
       " 7363: 'women',\n",
       " 7237: 'wear',\n",
       " 3638: 'kinda',\n",
       " 2796: 'glasses',\n",
       " 4617: 'opinions',\n",
       " 7299: 'white',\n",
       " 2060: 'dudes',\n",
       " 4422: 'neighborhood',\n",
       " 3981: 'major',\n",
       " 1217: 'city',\n",
       " 197: 'america',\n",
       " 7453: 'yoko',\n",
       " 4601: 'ono',\n",
       " 2359: 'factory',\n",
       " 7280: 'whats',\n",
       " 7421: 'wrong',\n",
       " 2426: 'feel',\n",
       " 4896: 'picturesque',\n",
       " 7268: 'wes',\n",
       " 215: 'anderson',\n",
       " 4318: 'movie',\n",
       " 6607: 'teach',\n",
       " 1483: 'cool',\n",
       " 6441: 'stuff',\n",
       " 7165: 'voting',\n",
       " 5371: 'recycling',\n",
       " 1934: 'disturbing',\n",
       " 1948: 'documentaries',\n",
       " 3419: 'introduce',\n",
       " 3208: 'hot',\n",
       " 3179: 'hookin',\n",
       " 4094: 'mean',\n",
       " 3985: 'makes',\n",
       " 5051: 'powerful',\n",
       " 2106: 'eats',\n",
       " 5217: 'pussy',\n",
       " 19: 'absorbing',\n",
       " 5110: 'privilege',\n",
       " 2227: 'entitlement',\n",
       " 4266: 'money',\n",
       " 3146: 'hole',\n",
       " 7168: 'vulnerable',\n",
       " 1610: 'crush',\n",
       " 3036: 'head',\n",
       " 4260: 'moment',\n",
       " 3629: 'kill',\n",
       " 789: 'brains',\n",
       " 1331: 'colonize',\n",
       " 1332: 'colonizer',\n",
       " 3667: 'knowbut',\n",
       " 6699: 'think',\n",
       " 4033: 'marriage',\n",
       " 4453: 'nice',\n",
       " 6162: 'somebody',\n",
       " 5263: 'race',\n",
       " 85: 'advantage',\n",
       " 5269: 'racist',\n",
       " 5713: 'say',\n",
       " 2333: 'explain',\n",
       " 2952: 'halffilipino',\n",
       " 2954: 'halfjapanese',\n",
       " 2950: 'halfchinese',\n",
       " 2957: 'halfvietnamese',\n",
       " 6221: 'spend',\n",
       " 4832: 'percent',\n",
       " 5926: 'shitting',\n",
       " 3674: 'korean',\n",
       " 193: 'amazing',\n",
       " 3917: 'love',\n",
       " 870: 'built',\n",
       " 3670: 'knowmy',\n",
       " 778: 'boyfriend',\n",
       " 1616: 'cuban',\n",
       " 4164: 'mexican',\n",
       " 2931: 'guys',\n",
       " 300: 'arent',\n",
       " 7006: 'underrated',\n",
       " 5868: 'sexiest',\n",
       " 2942: 'hair',\n",
       " 4411: 'neck',\n",
       " 3987: 'making',\n",
       " 1962: 'dolphin',\n",
       " 6118: 'smooth',\n",
       " 6082: 'slip',\n",
       " 6073: 'slide',\n",
       " 665: 'black',\n",
       " 2505: 'fish',\n",
       " 6747: 'tilikum',\n",
       " 554: 'bed',\n",
       " 4606: 'oohwee',\n",
       " 4147: 'mess',\n",
       " 3522: 'jewish',\n",
       " 5372: 'red',\n",
       " 3354: 'inflamed',\n",
       " 340: 'ask',\n",
       " 2305: 'exfoliated',\n",
       " 6775: 'today',\n",
       " 3495: 'jdate',\n",
       " 3888: 'loofah',\n",
       " 6673: 'thanks',\n",
       " 5623: 'rug',\n",
       " 899: 'burn',\n",
       " 421: 'avi',\n",
       " 4551: 'odor',\n",
       " 6104: 'smell',\n",
       " 5486: 'responsibility',\n",
       " 6989: 'umami',\n",
       " 2534: 'flavor',\n",
       " 1348: 'comes',\n",
       " 2662: 'fromi',\n",
       " 7040: 'unspoken',\n",
       " 7008: 'understanding',\n",
       " 2951: 'halffancy',\n",
       " 2955: 'halfjungle',\n",
       " 1857: 'difference',\n",
       " 2387: 'fancy',\n",
       " 338: 'asians',\n",
       " 1173: 'chinese',\n",
       " 3488: 'japanese',\n",
       " 3206: 'host',\n",
       " 4582: 'olympics',\n",
       " 3576: 'jungle',\n",
       " 1907: 'diseases',\n",
       " 1859: 'different',\n",
       " 2099: 'east',\n",
       " 1299: 'coast',\n",
       " 5109: 'private',\n",
       " 4952: 'playing',\n",
       " 3685: 'lacrosse',\n",
       " 3756: 'learning',\n",
       " 3721: 'latin',\n",
       " 1149: 'chess',\n",
       " 5624: 'rugby',\n",
       " 2471: 'filipino',\n",
       " 1002: 'carlton',\n",
       " 1851: 'didnt',\n",
       " 7134: 'vietnamese',\n",
       " 1696: 'dates',\n",
       " 6797: 'took',\n",
       " 5489: 'restaurant',\n",
       " 7269: 'west',\n",
       " 3900: 'los',\n",
       " 222: 'angeles',\n",
       " 945: 'called',\n",
       " 4870: 'pho',\n",
       " 409: 'authentic',\n",
       " 5323: 'read',\n",
       " 7444: 'yelp',\n",
       " 4513: 'number',\n",
       " 5789: 'second',\n",
       " 525: 'bathroom',\n",
       " 3774: 'legit',\n",
       " 1984: 'double',\n",
       " 6501: 'supply',\n",
       " 1276: 'closet',\n",
       " 2699: 'gallons',\n",
       " 676: 'bleach',\n",
       " 374: 'atm',\n",
       " 3953: 'machine',\n",
       " 2863: 'grandma',\n",
       " 2797: 'glaucoma',\n",
       " 4384: 'napping',\n",
       " 1495: 'corner',\n",
       " 7177: 'wait',\n",
       " 6282: 'staff',\n",
       " 3758: 'leave',\n",
       " 1717: 'deaf',\n",
       " 2185: 'emotionally',\n",
       " 22: 'abused',\n",
       " 6807: 'total',\n",
       " 617: 'big',\n",
       " 3123: 'hippies',\n",
       " 454: 'backpack',\n",
       " 6193: 'southeast',\n",
       " 335: 'asia',\n",
       " 7450: 'yoga',\n",
       " 437: 'ayahuasca',\n",
       " 1067: 'ceremonies',\n",
       " 5997: 'silent',\n",
       " 5498: 'retreats',\n",
       " 4788: 'pay',\n",
       " 5971: 'shut',\n",
       " 7252: 'weekend',\n",
       " 2806: 'glutenfree',\n",
       " 4098: 'means',\n",
       " 800: 'bread',\n",
       " 6596: 'tastes',\n",
       " 2640: 'freerange',\n",
       " 1153: 'chewbacca',\n",
       " 3782: 'lesbian',\n",
       " 6710: 'thousand',\n",
       " 1663: 'daily',\n",
       " 2453: 'fiber',\n",
       " 6246: 'spoken',\n",
       " 7376: 'word',\n",
       " 4972: 'poetry',\n",
       " 5235: 'queef',\n",
       " 5927: 'shitty',\n",
       " 4970: 'poem',\n",
       " 6503: 'supporting',\n",
       " 933: 'caitlyn',\n",
       " 3505: 'jenner',\n",
       " 2692: 'funny',\n",
       " 3124: 'hippydippy',\n",
       " 1957: 'doing',\n",
       " 3315: 'impression',\n",
       " 5768: 'scrolls',\n",
       " 7188: 'wall',\n",
       " 860: 'buddha',\n",
       " 4904: 'piggy',\n",
       " 495: 'bank',\n",
       " 4900: 'pier',\n",
       " 3311: 'imports',\n",
       " 5167: 'providing',\n",
       " 2823: 'good',\n",
       " 2442: 'feng',\n",
       " 5969: 'shui',\n",
       " 3213: 'house',\n",
       " 7438: 'years',\n",
       " 6130: 'sneaking',\n",
       " 6524: 'suspicion',\n",
       " 5153: 'propose',\n",
       " 5082: 'pressuring',\n",
       " 7170: 'wacky',\n",
       " 3425: 'intuition',\n",
       " 5152: 'proposals',\n",
       " 7380: 'work',\n",
       " 3324: 'incept',\n",
       " 3270: 'idea',\n",
       " 4011: 'mans',\n",
       " 4764: 'passively',\n",
       " 1952: 'doesnt',\n",
       " 4148: 'message',\n",
       " 2345: 'extremely',\n",
       " 114: 'aggressively',\n",
       " 6713: 'threaten',\n",
       " 60: 'actually',\n",
       " 3760: 'leaving',\n",
       " 4572: 'old',\n",
       " 3716: 'late',\n",
       " 4444: 'new',\n",
       " 6306: 'start',\n",
       " 4007: 'manipulation',\n",
       " 1654: 'cycle',\n",
       " 6355: 'stick',\n",
       " 2572: 'focus',\n",
       " 6862: 'trapping',\n",
       " 4369: 'nag',\n",
       " 4660: 'outta',\n",
       " 7232: 'weak',\n",
       " 1048: 'caves',\n",
       " 2764: 'gets',\n",
       " 2422: 'fed',\n",
       " 2485: 'fine',\n",
       " 4037: 'marry',\n",
       " 5154: 'proposed',\n",
       " 3889: 'look',\n",
       " 2286: 'exact',\n",
       " 5547: 'ring',\n",
       " 7199: 'wanted',\n",
       " 4079: 'maybe',\n",
       " 4916: 'pinterest',\n",
       " 4694: 'page',\n",
       " 5841: 'sent',\n",
       " 595: 'best',\n",
       " 2650: 'friend',\n",
       " 5831: 'send',\n",
       " 4917: 'pinterested',\n",
       " 2208: 'engaged',\n",
       " 5697: 'saturday',\n",
       " 762: 'bought',\n",
       " 2016: 'dress',\n",
       " 2581: 'following',\n",
       " 6930: 'tuesday',\n",
       " 6891: 'tried',\n",
       " 5327: 'ready',\n",
       " 5552: 'ripe',\n",
       " 5604: 'rotten',\n",
       " 489: 'banana',\n",
       " 6516: 'surprised',\n",
       " 4564: 'offstage',\n",
       " 1387: 'completely',\n",
       " 5361: 'recognize',\n",
       " 4846: 'personality',\n",
       " 6151: 'soft',\n",
       " 4520: 'nurturing',\n",
       " 1964: 'domestic',\n",
       " 7271: 'weve',\n",
       " 3469: 'ive',\n",
       " 4687: 'packed',\n",
       " 3936: 'lunch',\n",
       " 6017: 'single',\n",
       " 3067: 'hed',\n",
       " 1791: 'dependent',\n",
       " 2851: 'graduated',\n",
       " 2424: 'feed',\n",
       " 2826: 'goodness',\n",
       " 3056: 'heart',\n",
       " 3431: 'investment',\n",
       " 2481: 'financial',\n",
       " 5325: 'reading',\n",
       " 738: 'book',\n",
       " 5913: 'sheryl',\n",
       " 5677: 'sandberg',\n",
       " 5914: 'shes',\n",
       " 1479: 'coo',\n",
       " 2354: 'facebook',\n",
       " 7424: 'wrote',\n",
       " 5545: 'riled',\n",
       " 994: 'careers',\n",
       " 6580: 'talking',\n",
       " 1079: 'challenge',\n",
       " 6025: 'sit',\n",
       " 6565: 'table',\n",
       " 5555: 'rise',\n",
       " 3751: 'lean',\n",
       " 3812: 'lie',\n",
       " 7198: 'want',\n",
       " 2438: 'feminism',\n",
       " 3530: 'job',\n",
       " 7064: 'used',\n",
       " 6099: 'smart',\n",
       " 1460: 'continue',\n",
       " 2065: 'dumb',\n",
       " 1061: 'century',\n",
       " 2916: 'guess',\n",
       " 6327: 'stay',\n",
       " 6120: 'snacks',\n",
       " 7221: 'watch',\n",
       " 2162: 'ellen',\n",
       " 6446: 'stupid',\n",
       " 5328: 'real',\n",
       " 653: 'bitch',\n",
       " 5626: 'ruined',\n",
       " 2318: 'expected',\n",
       " 3052: 'hear',\n",
       " 4879: 'phrase',\n",
       " 1985: 'doubleincome',\n",
       " 3215: 'household',\n",
       " 7052: 'upset',\n",
       " 1363: 'comments',\n",
       " 4624: 'options',\n",
       " 2637: 'free',\n",
       " 7039: 'unscheduled',\n",
       " 7041: 'unsupervised',\n",
       " 3310: 'importantly',\n",
       " 6247: 'sponsored',\n",
       " 5925: 'shittier',\n",
       " 2584: 'food',\n",
       " 2088: 'earn',\n",
       " 3458: 'ita',\n",
       " 7184: 'walk',\n",
       " 6692: 'theyll',\n",
       " 3563: 'judgmental',\n",
       " 3218: 'housewives',\n",
       " 6397: 'street',\n",
       " 3217: 'housewife',\n",
       " 7186: 'walking',\n",
       " 4051: 'massages',\n",
       " 3935: 'lululemon',\n",
       " 4719: 'pants',\n",
       " 2747: 'genius',\n",
       " 5496: 'retiredi',\n",
       " 7417: 'write',\n",
       " 2645: 'fresh',\n",
       " 713: 'boat',\n",
       " 6: 'abc',\n",
       " 2880: 'great',\n",
       " 1546: 'coworkers',\n",
       " 7419: 'writing',\n",
       " 6646: 'terms',\n",
       " 3531: 'jobs',\n",
       " 4560: 'office',\n",
       " 6045: 'skin',\n",
       " 5784: 'seat',\n",
       " 7063: 'use',\n",
       " 6780: 'toilet',\n",
       " 4721: 'paper',\n",
       " 1539: 'cover',\n",
       " 6753: 'times',\n",
       " 5653: 'sadass',\n",
       " 4092: 'meal',\n",
       " 4592: 'oneply',\n",
       " 5206: 'purposely',\n",
       " 1861: 'difficult',\n",
       " 5188: 'pull',\n",
       " 6919: 'try',\n",
       " 5312: 'ration',\n",
       " 1369: 'communist',\n",
       " 2129: 'effective',\n",
       " 1763: 'dehydrates',\n",
       " 7342: 'wiping',\n",
       " 1803: 'desert',\n",
       " 3849: 'literally',\n",
       " 6204: 'spat',\n",
       " 1710: 'days',\n",
       " 115: 'ago',\n",
       " 3950: 'macgyver',\n",
       " 443: 'baby',\n",
       " 7340: 'wipe',\n",
       " 4252: 'moisten',\n",
       " 449: 'backfired',\n",
       " 2488: 'fingers',\n",
       " 834: 'broke',\n",
       " 1866: 'digitally',\n",
       " 6358: 'stimulated',\n",
       " 1971: 'doo',\n",
       " 2489: 'finish',\n",
       " 5641: 'rushed',\n",
       " 4727: 'paranoid',\n",
       " 5934: 'shoes',\n",
       " 7005: 'underneath',\n",
       " 6288: 'stall',\n",
       " 1535: 'courtneys',\n",
       " 3846: 'listening',\n",
       " 7179: 'waiting',\n",
       " 6754: 'timing',\n",
       " 3250: 'hurry',\n",
       " 2429: 'feels',\n",
       " 935: 'caked',\n",
       " 3884: 'long',\n",
       " 1684: 'dare',\n",
       " 5755: 'scratch',\n",
       " 7011: 'underwear',\n",
       " 2197: 'end',\n",
       " 3892: 'looks',\n",
       " 2829: 'goonies',\n",
       " 4329: 'muffle',\n",
       " 7398: 'worry',\n",
       " 7110: 'velocity',\n",
       " 6270: 'squeeze',\n",
       " 1132: 'cheeks',\n",
       " 6508: 'sure',\n",
       " 6085: 'slow',\n",
       " 6334: 'steady',\n",
       " 4684: 'pace',\n",
       " 7033: 'unpredictable',\n",
       " 4480: 'noise',\n",
       " 6467: 'suddenly',\n",
       " 2247: 'escapes',\n",
       " 828: 'brings',\n",
       " 1746: 'deep',\n",
       " 5887: 'shame',\n",
       " 695: 'blow',\n",
       " 2108: 'echo',\n",
       " 5509: 'reverberate',\n",
       " 2202: 'ends',\n",
       " 2962: 'hallways',\n",
       " 7224: 'watching',\n",
       " 4439: 'netflix',\n",
       " 3441: 'ipad',\n",
       " 747: 'boring',\n",
       " 5459: 'repressed',\n",
       " 5924: 'shits',\n",
       " 3845: 'listen',\n",
       " 4969: 'podcasts',\n",
       " 4934: 'planet',\n",
       " 7201: 'wantyou',\n",
       " 1930: 'distracting',\n",
       " 3901: 'lose',\n",
       " 5480: 'respect',\n",
       " 3145: 'holds',\n",
       " 6182: 'sort',\n",
       " 1577: 'credence',\n",
       " 3053: 'heard',\n",
       " 4433: 'nerve',\n",
       " 490: 'bananas',\n",
       " 2886: 'green',\n",
       " 479: 'ballet',\n",
       " 2533: 'flats',\n",
       " 2408: 'fatherinlaw',\n",
       " 6027: 'sitdown',\n",
       " 5355: 'recently',\n",
       " 6578: 'talk',\n",
       " 5166: 'provide',\n",
       " 1163: 'children',\n",
       " 5111: 'privileged',\n",
       " 1161: 'childhood',\n",
       " 6629: 'telling',\n",
       " 1471: 'conversation',\n",
       " 6169: 'son',\n",
       " 7007: 'understand',\n",
       " 2089: 'earning',\n",
       " 1186: 'choose',\n",
       " 5488: 'rest',\n",
       " 1194: 'chose',\n",
       " 5139: 'promise',\n",
       " 2087: 'early',\n",
       " 5497: 'retirement',\n",
       " 5663: 'said',\n",
       " 4099: 'meant',\n",
       " 1856: 'dieting',\n",
       " 2105: 'eating',\n",
       " 2649: 'fried',\n",
       " 1156: 'chicken',\n",
       " 2678: 'fulfilling',\n",
       " 1814: 'destiny',\n",
       " 1211: 'circle',\n",
       " 2350: 'eyelashes',\n",
       " 4324: 'mrs',\n",
       " 4690: 'pacman',\n",
       " 3787: 'lets',\n",
       " 5373: 'redecoratei',\n",
       " 1913: 'disgusting',\n",
       " 4851: 'pervert',\n",
       " 2897: 'gross',\n",
       " 2478: 'filthy',\n",
       " 228: 'animal',\n",
       " 6307: 'started',\n",
       " 5017: 'porn',\n",
       " 7461: 'young',\n",
       " 106: 'age',\n",
       " 2997: 'happens',\n",
       " 7471: 'yyou',\n",
       " 5981: 'sicker',\n",
       " 3292: 'images',\n",
       " 1565: 'crave',\n",
       " 3411: 'internet',\n",
       " 7459: 'youi',\n",
       " 3278: 'idiot',\n",
       " 5333: 'realize',\n",
       " 7265: 'went',\n",
       " 1558: 'craigslist',\n",
       " 5033: 'posted',\n",
       " 6759: 'tiny',\n",
       " 2436: 'female',\n",
       " 5802: 'seeking',\n",
       " 206: 'anal',\n",
       " 1560: 'crash',\n",
       " 3988: 'male',\n",
       " 3043: 'heads',\n",
       " 7025: 'universe',\n",
       " 6012: 'simultaneously',\n",
       " 2337: 'explode',\n",
       " 2631: 'freaked',\n",
       " 5724: 'scared',\n",
       " 4698: 'pain',\n",
       " 131: 'aint',\n",
       " 7229: 'wax',\n",
       " 2349: 'eyebrows',\n",
       " 6184: 'sorts',\n",
       " 1570: 'crazy',\n",
       " 1842: 'dick',\n",
       " 2278: 'evil',\n",
       " 5794: 'secrets',\n",
       " 3814: 'lies',\n",
       " 5846: 'sephora',\n",
       " 5219: 'puts',\n",
       " 6701: 'thinking',\n",
       " 1658: 'dad',\n",
       " 1700: 'dave',\n",
       " 2270: 'eventually',\n",
       " 1091: 'change',\n",
       " 1123: 'cheat',\n",
       " 3408: 'interesting',\n",
       " 3147: 'holes',\n",
       " 7460: 'youll',\n",
       " 5873: 'sexually',\n",
       " 54: 'active',\n",
       " 5490: 'result',\n",
       " 3850: 'little',\n",
       " 652: 'bit',\n",
       " 6404: 'stretched',\n",
       " 2480: 'finally',\n",
       " 2435: 'felt',\n",
       " 1088: 'chance',\n",
       " 3968: 'magical',\n",
       " 2393: 'fantasy',\n",
       " 5030: 'possible',\n",
       " 1897: 'discover',\n",
       " 5156: 'prostate',\n",
       " 1434: 'conqueror',\n",
       " 3030: 'havent',\n",
       " 6873: 'treat',\n",
       " 6795: 'tonight',\n",
       " 3852: 'live',\n",
       " 7455: 'yolo',\n",
       " 6127: 'sneak',\n",
       " 5215: 'pushpush',\n",
       " 6943: 'tushtush',\n",
       " 364: 'atari',\n",
       " 5475: 'resistance',\n",
       " 6273: 'squirmy',\n",
       " 7395: 'wormy',\n",
       " 6733: 'thumb',\n",
       " 6459: 'succeed',\n",
       " 2728: 'gay',\n",
       " 2415: 'fear',\n",
       " 6941: 'turns',\n",
       " 2251: 'especially',\n",
       " 4157: 'metamorphosizes',\n",
       " 4954: 'pleasure',\n",
       " 2347: 'eye',\n",
       " 1898: 'discovered',\n",
       " 4473: 'nirvana',\n",
       " 3688: 'lady',\n",
       " 1267: 'clit',\n",
       " 2352: 'eyes',\n",
       " 3898: 'lord',\n",
       " 5546: 'rim',\n",
       " 7015: 'unfortunately',\n",
       " 2635: 'freaky',\n",
       " 341: 'asked',\n",
       " 6202: 'spank',\n",
       " 1951: 'does',\n",
       " 21: 'abuse',\n",
       " 6425: 'strongheaded',\n",
       " 3913: 'loudmouthed',\n",
       " 1063: 'ceos',\n",
       " 5607: 'roughed',\n",
       " 7200: 'wants',\n",
       " 1466: 'control',\n",
       " 5557: 'risk',\n",
       " 1181: 'choke',\n",
       " 6762: 'tired',\n",
       " 750: 'boss',\n",
       " 556: 'bedroom',\n",
       " 4297: 'motherfucker',\n",
       " 3302: 'impact',\n",
       " 487: 'ban',\n",
       " 752: 'bossy',\n",
       " 2155: 'elementary',\n",
       " 5737: 'schools',\n",
       " 5870: 'sexist',\n",
       " 780: 'boys',\n",
       " 3390: 'instead',\n",
       " 5716: 'saying',\n",
       " 6505: 'supposed',\n",
       " 2302: 'executive',\n",
       " 3747: 'leadership',\n",
       " 6044: 'skills',\n",
       " 5609: 'roundabout',\n",
       " 1627: 'cunt',\n",
       " 2482: 'financially',\n",
       " 1069: 'certain',\n",
       " 4974: 'point',\n",
       " 1527: 'couple',\n",
       " 1350: 'comfortably',\n",
       " 94: 'afford',\n",
       " 6070: 'sliced',\n",
       " 4000: 'mango',\n",
       " 2585: 'foods',\n",
       " 3331: 'income',\n",
       " 785: 'bracket',\n",
       " 6417: 'striving',\n",
       " 7468: 'youve',\n",
       " 4377: 'named',\n",
       " 4475: 'noah',\n",
       " 5348: 'rebecca',\n",
       " 3653: 'kiwi',\n",
       " 1681: 'danielle',\n",
       " 4913: 'pineapple',\n",
       " 10: 'able',\n",
       " 6421: 'stroll',\n",
       " 5985: 'sidewalk',\n",
       " 5233: 'quarter',\n",
       " 5098: 'princess',\n",
       " 7065: 'useful',\n",
       " 88: 'advice',\n",
       " 841: 'brothers',\n",
       " 6024: 'sisters',\n",
       " 4701: 'paintballing',\n",
       " 7133: 'vietnam',\n",
       " 7118: 'veteran',\n",
       " 5859: 'seven',\n",
       " 2948: 'half',\n",
       " 4278: 'months',\n",
       " 5066: 'pregnant',\n",
       " 5308: 'rare',\n",
       " 1352: 'comic',\n",
       " 4835: 'perform',\n",
       " 1353: 'comics',\n",
       " 2738: 'generally',\n",
       " 1017: 'case',\n",
       " 7251: 'week',\n",
       " 444: 'babys',\n",
       " 4897: 'piece',\n",
       " 240: 'annoying',\n",
       " 1662: 'dads',\n",
       " 398: 'audience',\n",
       " 3110: 'hilarious',\n",
       " 3276: 'identify',\n",
       " 2378: 'fame',\n",
       " 6543: 'swells',\n",
       " 5412: 'relatable',\n",
       " 6466: 'sudden',\n",
       " 1103: 'chapping',\n",
       " 4471: 'nipples',\n",
       " 2425: 'feeding',\n",
       " 7238: 'wearing',\n",
       " 2663: 'frozen',\n",
       " 1838: 'diaper',\n",
       " 4416: 'needs',\n",
       " 5964: 'shredding',\n",
       " 2993: 'happen',\n",
       " 6294: 'standup',\n",
       " 6461: 'successful',\n",
       " 2385: 'famous',\n",
       " 1895: 'discouraged',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el corpus y el diccionario ubicación:palabra, necesitamos especificar otros 2 parámetros:\n",
    "- El total de temas y\n",
    "- El total de iteraciones en el entrenamiento. \n",
    "\n",
    "Probamos con 2 temas y veremos si el resultado tiene sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"like\" + 0.016*\"im\" + 0.013*\"know\" + 0.011*\"just\" + 0.010*\"dont\" + 0.009*\"said\" + 0.009*\"right\" + 0.007*\"thats\" + 0.006*\"youre\" + 0.006*\"people\"'),\n",
       " (1,\n",
       "  '0.030*\"like\" + 0.017*\"just\" + 0.016*\"im\" + 0.015*\"dont\" + 0.014*\"know\" + 0.010*\"right\" + 0.010*\"thats\" + 0.009*\"youre\" + 0.008*\"people\" + 0.008*\"gonna\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(222)\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"like\" + 0.017*\"im\" + 0.015*\"know\" + 0.013*\"just\" + 0.012*\"dont\" + 0.011*\"said\" + 0.008*\"right\" + 0.008*\"thats\" + 0.007*\"think\" + 0.007*\"people\"'),\n",
       " (1,\n",
       "  '0.033*\"like\" + 0.019*\"just\" + 0.015*\"know\" + 0.015*\"dont\" + 0.014*\"im\" + 0.010*\"thats\" + 0.010*\"right\" + 0.009*\"people\" + 0.009*\"youre\" + 0.009*\"gonna\"'),\n",
       " (2,\n",
       "  '0.023*\"like\" + 0.017*\"im\" + 0.011*\"know\" + 0.010*\"dont\" + 0.010*\"right\" + 0.009*\"just\" + 0.007*\"got\" + 0.007*\"youre\" + 0.007*\"thats\" + 0.007*\"say\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "np.random.seed(222)\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.029*\"like\" + 0.018*\"im\" + 0.016*\"know\" + 0.014*\"just\" + 0.012*\"dont\" + 0.009*\"said\" + 0.009*\"right\" + 0.009*\"thats\" + 0.008*\"youre\" + 0.007*\"people\"'),\n",
       " (1,\n",
       "  '0.032*\"like\" + 0.017*\"just\" + 0.016*\"im\" + 0.015*\"know\" + 0.014*\"dont\" + 0.011*\"right\" + 0.009*\"thats\" + 0.008*\"got\" + 0.008*\"gonna\" + 0.008*\"youre\"'),\n",
       " (2,\n",
       "  '0.001*\"like\" + 0.001*\"im\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"dont\" + 0.001*\"right\" + 0.001*\"youre\" + 0.001*\"thats\" + 0.000*\"people\" + 0.000*\"got\"'),\n",
       " (3,\n",
       "  '0.022*\"like\" + 0.015*\"im\" + 0.015*\"dont\" + 0.013*\"just\" + 0.013*\"fucking\" + 0.013*\"people\" + 0.010*\"right\" + 0.010*\"know\" + 0.009*\"thats\" + 0.009*\"fuck\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "np.random.seed(222)\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que obtenemos es la probabilidad de que una palabra, aparezca en un tema.\n",
    "Pero los resultados son pobres.  Hemos probado a mejorarlo, modificando los parámetros, probemos ahora modificando los términos usados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic Modeling - Prueba #2 (Sólo sustantivos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un truco habitual suele ser usar sólo sustantivos, sólo adjetivos, ...\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html. -> para comprobar la etiqueta para filtrar por sustantivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para extraer los sustantivos de un texto\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def sustantivos(texto):\n",
    "    '''Dada una cadena de texto, se tokeniza y devuelve sólo los sustantivos.'''\n",
    "    # Aquí es donde nos quedamos sólo con los sustantivos.\n",
    "    es_sustantivo = lambda pos: pos[:2] == 'NN'\n",
    "    \n",
    "    tokenizado = word_tokenize(texto)\n",
    "    todo_sustantivos = [palabra for (palabra, pos) in pos_tag(tokenizado) if es_sustantivo(pos)] \n",
    "    return ' '.join(todo_sustantivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies and gentlemen please welcome to the sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank you thank you thank you san francisco th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>all right thank you thank you very much thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>bo what old macdonald had a farm e i e i o and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>this is dave he tells dirty jokes for a living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats up davis whats up im home i had to bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies and gentlemen please welcome to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies and gentlemen welcome joe rogan  wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>all right petunia wish me luck out there you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>introfade the music out lets roll hold there l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thank you thanks thank you guys hey se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello hello how you doing great thank you wow ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcripcion\n",
       "ali      ladies and gentlemen please welcome to the sta...\n",
       "anthony  thank you thank you thank you san francisco th...\n",
       "bill      all right thank you thank you very much thank...\n",
       "bo       bo what old macdonald had a farm e i e i o and...\n",
       "dave     this is dave he tells dirty jokes for a living...\n",
       "hasan      whats up davis whats up im home i had to bri...\n",
       "jim         ladies and gentlemen please welcome to the ...\n",
       "joe         ladies and gentlemen welcome joe rogan  wha...\n",
       "john     all right petunia wish me luck out there you w...\n",
       "louis    introfade the music out lets roll hold there l...\n",
       "mike     wow hey thank you thanks thank you guys hey se...\n",
       "ricky    hello hello how you doing great thank you wow ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los datos limpios generados previamente\n",
    "datos_limpios = pd.read_pickle('datos_limpios.pkl')\n",
    "datos_limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\borja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargamos la librería para poder normalizar las palabras, según su contexto y análisis morfológico.\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies gentlemen stage ali hi thank hello na s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank thank people i em i francisco city world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>thank thank pleasure georgia area oasis i june...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>macdonald farm e i o farm pig e i i snort macd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>jokes living stare work profound train thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats davis whats home i netflix la york i son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies gentlemen stage mr jim jefferies thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies gentlemen joe fuck thanks phone fuckfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>petunia thats hello hello chicago thank crowd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>music lets lights lights thank i i place place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thanks look insane years everyone i id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello thank fuck thank im gon youre weve money...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcripcion\n",
       "ali      ladies gentlemen stage ali hi thank hello na s...\n",
       "anthony  thank thank people i em i francisco city world...\n",
       "bill     thank thank pleasure georgia area oasis i june...\n",
       "bo       macdonald farm e i o farm pig e i i snort macd...\n",
       "dave     jokes living stare work profound train thought...\n",
       "hasan    whats davis whats home i netflix la york i son...\n",
       "jim      ladies gentlemen stage mr jim jefferies thank ...\n",
       "joe      ladies gentlemen joe fuck thanks phone fuckfac...\n",
       "john     petunia thats hello hello chicago thank crowd ...\n",
       "louis    music lets lights lights thank i i place place...\n",
       "mike     wow hey thanks look insane years everyone i id...\n",
       "ricky    hello thank fuck thank im gon youre weve money..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos los sustantivos\n",
    "datos_sustantivos = pd.DataFrame(datos_limpios ['transcripcion'].apply(sustantivos))\n",
    "datos_sustantivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>ze</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 4648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aah  abc  abcs  ability  \\\n",
       "ali                 0                 0          0    0    1     0        0   \n",
       "anthony             0                 0          0    0    0     0        0   \n",
       "bill                0                 0          0    0    0     1        0   \n",
       "bo                  1                 1          1    0    0     0        1   \n",
       "dave                0                 0          0    0    0     0        0   \n",
       "hasan               0                 0          0    0    0     0        0   \n",
       "jim                 0                 0          0    0    0     0        0   \n",
       "joe                 0                 0          0    0    0     0        0   \n",
       "john                0                 0          0    0    0     0        0   \n",
       "louis               0                 0          0    3    0     0        0   \n",
       "mike                0                 0          0    0    0     0        0   \n",
       "ricky               0                 0          0    0    0     0        1   \n",
       "\n",
       "         abortion  abortions  abuse  ...  yummy  ze  zealand  zee  zeppelin  \\\n",
       "ali             0          0      0  ...      0   0        0    0         0   \n",
       "anthony         2          0      0  ...      0   0       10    0         0   \n",
       "bill            0          0      0  ...      0   1        0    0         0   \n",
       "bo              0          0      0  ...      0   0        0    0         0   \n",
       "dave            0          1      0  ...      0   0        0    0         0   \n",
       "hasan           0          0      0  ...      0   0        0    1         0   \n",
       "jim             0          0      0  ...      0   0        0    0         0   \n",
       "joe             0          0      1  ...      0   0        0    0         0   \n",
       "john            0          0      0  ...      0   0        0    0         0   \n",
       "louis           0          0      0  ...      0   0        0    0         0   \n",
       "mike            0          0      0  ...      0   0        0    0         2   \n",
       "ricky           0          0      0  ...      1   0        0    0         0   \n",
       "\n",
       "         zillion  zombie  zombies  zoo  éclair  \n",
       "ali            0       1        0    0       0  \n",
       "anthony        0       0        0    0       0  \n",
       "bill           1       1        1    0       0  \n",
       "bo             0       0        0    0       0  \n",
       "dave           0       0        0    0       0  \n",
       "hasan          0       0        0    0       0  \n",
       "jim            0       0        0    0       0  \n",
       "joe            0       0        0    0       0  \n",
       "john           0       0        0    0       1  \n",
       "louis          0       0        0    0       0  \n",
       "mike           0       0        0    0       0  \n",
       "ricky          0       0        0    1       0  \n",
       "\n",
       "[12 rows x 4648 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un nuevo corpus sólo con los sustantivos\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Quitamos las stopwords, puesto que vamos a generar un nuevo corpus\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said', \n",
    "                  'aaaaahhhhhhh', 'aaaaauuugghhhhhh', 'aaaahhhhh', 'aah', 'aaaaah']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Corpus sólo con sustantivos\n",
    "cvs = CountVectorizer(stop_words=\"english\")\n",
    "datos_cvs = cvs.fit_transform(datos_sustantivos['transcripcion'])\n",
    "datos_dtms = pd.DataFrame(datos_cvs.toarray(), columns=cvs.get_feature_names_out())\n",
    "datos_dtms.index = datos_sustantivos.index\n",
    "datos_dtms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el corpus gensim\n",
    "corpuss = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(datos_dtms.transpose()))\n",
    "\n",
    "# Generar el diccionario de vocabulario\n",
    "id2words = dict((v, k) for k, v in cvs.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"im\" + 0.013*\"people\" + 0.011*\"youre\" + 0.011*\"time\" + 0.011*\"thats\" + 0.007*\"life\" + 0.007*\"shit\" + 0.007*\"dont\" + 0.007*\"hes\" + 0.006*\"man\"'),\n",
       " (1,\n",
       "  '0.018*\"people\" + 0.014*\"im\" + 0.013*\"youre\" + 0.011*\"thats\" + 0.010*\"day\" + 0.009*\"thing\" + 0.008*\"time\" + 0.007*\"dont\" + 0.007*\"right\" + 0.007*\"fuck\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empezamos por 2 temas\n",
    "np.random.seed(222)\n",
    "ldas = models.LdaModel(corpus=corpuss, num_topics=2, id2word=id2words, passes=10)\n",
    "ldas.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"people\" + 0.011*\"shit\" + 0.011*\"time\" + 0.009*\"man\" + 0.007*\"fuck\" + 0.007*\"im\" + 0.006*\"thats\" + 0.006*\"lot\" + 0.006*\"didnt\" + 0.005*\"ahah\"'),\n",
       " (1,\n",
       "  '0.021*\"im\" + 0.012*\"thats\" + 0.012*\"youre\" + 0.011*\"people\" + 0.008*\"day\" + 0.008*\"time\" + 0.008*\"dont\" + 0.008*\"thing\" + 0.007*\"shit\" + 0.007*\"guy\"'),\n",
       " (2,\n",
       "  '0.019*\"people\" + 0.016*\"im\" + 0.014*\"youre\" + 0.012*\"thats\" + 0.010*\"time\" + 0.009*\"day\" + 0.008*\"thing\" + 0.008*\"life\" + 0.008*\"dont\" + 0.007*\"man\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 3\n",
    "np.random.seed(222)\n",
    "ldas = models.LdaModel(corpus=corpuss, num_topics=3, id2word=id2words, passes=10)\n",
    "ldas.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"im\" + 0.001*\"thats\" + 0.001*\"people\" + 0.001*\"youre\" + 0.001*\"time\" + 0.001*\"dont\" + 0.000*\"cause\" + 0.000*\"lot\" + 0.000*\"man\" + 0.000*\"shit\"'),\n",
       " (1,\n",
       "  '0.018*\"im\" + 0.013*\"youre\" + 0.011*\"people\" + 0.011*\"thats\" + 0.010*\"shit\" + 0.009*\"day\" + 0.009*\"thing\" + 0.008*\"time\" + 0.008*\"joke\" + 0.008*\"yeah\"'),\n",
       " (2,\n",
       "  '0.020*\"people\" + 0.016*\"im\" + 0.014*\"youre\" + 0.012*\"thats\" + 0.011*\"time\" + 0.009*\"man\" + 0.008*\"day\" + 0.008*\"shit\" + 0.008*\"thing\" + 0.008*\"life\"'),\n",
       " (3,\n",
       "  '0.019*\"im\" + 0.012*\"thats\" + 0.010*\"cause\" + 0.009*\"people\" + 0.008*\"youre\" + 0.008*\"dont\" + 0.008*\"kind\" + 0.008*\"point\" + 0.007*\"time\" + 0.006*\"way\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 4\n",
    "np.random.seed(222)\n",
    "ldas = models.LdaModel(corpus=corpuss, num_topics=4, id2word=id2words, passes=10)\n",
    "ldas.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"im\" + 0.001*\"people\" + 0.001*\"thats\" + 0.001*\"youre\" + 0.001*\"time\" + 0.000*\"man\" + 0.000*\"lot\" + 0.000*\"shit\" + 0.000*\"dont\" + 0.000*\"life\"'),\n",
       " (1,\n",
       "  '0.015*\"im\" + 0.014*\"joke\" + 0.012*\"day\" + 0.010*\"people\" + 0.008*\"thats\" + 0.008*\"time\" + 0.008*\"thing\" + 0.008*\"anthony\" + 0.007*\"school\" + 0.006*\"family\"'),\n",
       " (2,\n",
       "  '0.021*\"people\" + 0.018*\"im\" + 0.015*\"youre\" + 0.013*\"thats\" + 0.010*\"time\" + 0.010*\"shit\" + 0.010*\"thing\" + 0.009*\"life\" + 0.009*\"man\" + 0.009*\"fuck\"'),\n",
       " (3,\n",
       "  '0.022*\"im\" + 0.011*\"thats\" + 0.010*\"cause\" + 0.009*\"point\" + 0.008*\"dont\" + 0.008*\"people\" + 0.008*\"kind\" + 0.007*\"youre\" + 0.007*\"time\" + 0.006*\"way\"'),\n",
       " (4,\n",
       "  '0.012*\"im\" + 0.011*\"time\" + 0.011*\"youre\" + 0.011*\"people\" + 0.010*\"thats\" + 0.008*\"day\" + 0.007*\"way\" + 0.006*\"man\" + 0.006*\"lot\" + 0.006*\"shit\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 5\n",
    "np.random.seed(222)\n",
    "ldas = models.LdaModel(corpus=corpuss, num_topics=5, id2word=id2words, passes=10)\n",
    "ldas.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Prueba #3 (Sustantivos y Adjetivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer los sustantivos y adjetivos\n",
    "def sust_adj(texto):\n",
    "    '''Dado un texto, lo tokeniza y devuelve sólo los sustantivos y adjetivos.'''\n",
    "    es_sust_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenizado = word_tokenize(texto)\n",
    "    todo_sust_adj = [palabra for (palabra, pos) in pos_tag(tokenizado) if es_sust_adj(pos)] \n",
    "    return ' '.join(todo_sust_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies gentlemen welcome stage ali wong hi wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank san francisco thank good people surprise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>right thank thank pleasure greater atlanta geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>old macdonald farm e i i o farm pig e i i snor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>dirty jokes living stare most hard work profou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats davis whats im home i netflix special la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies gentlemen welcome stage mr jim jefferie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies gentlemen joe fuck san francisco thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>right petunia august thats good right hello he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>music lets lights lights thank much i i i nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thanks hey seattle nice look crazy ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello great thank fuck thank lovely welcome im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcripcion\n",
       "ali      ladies gentlemen welcome stage ali wong hi wel...\n",
       "anthony  thank san francisco thank good people surprise...\n",
       "bill     right thank thank pleasure greater atlanta geo...\n",
       "bo       old macdonald farm e i i o farm pig e i i snor...\n",
       "dave     dirty jokes living stare most hard work profou...\n",
       "hasan    whats davis whats im home i netflix special la...\n",
       "jim      ladies gentlemen welcome stage mr jim jefferie...\n",
       "joe      ladies gentlemen joe fuck san francisco thanks...\n",
       "john     right petunia august thats good right hello he...\n",
       "louis    music lets lights lights thank much i i i nice...\n",
       "mike     wow hey thanks hey seattle nice look crazy ins...\n",
       "ricky    hello great thank fuck thank lovely welcome im..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos la función a los datos limpios\n",
    "datos_sust_adj = pd.DataFrame(datos_limpios['transcripcion'].apply(sust_adj))\n",
    "datos_sust_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>ze</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 5591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaah  aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aah  abc  abcs  \\\n",
       "ali           0             0                 0          0    0    1     0   \n",
       "anthony       0             0                 0          0    0    0     0   \n",
       "bill          1             0                 0          0    0    0     1   \n",
       "bo            0             1                 1          1    0    0     0   \n",
       "dave          0             0                 0          0    0    0     0   \n",
       "hasan         0             0                 0          0    0    0     0   \n",
       "jim           0             0                 0          0    0    0     0   \n",
       "joe           0             0                 0          0    0    0     0   \n",
       "john          0             0                 0          0    0    0     0   \n",
       "louis         0             0                 0          0    3    0     0   \n",
       "mike          0             0                 0          0    0    0     0   \n",
       "ricky         0             0                 0          0    0    0     0   \n",
       "\n",
       "         ability  abject  able  ...  ze  zealand  zee  zeppelin  zero  \\\n",
       "ali            0       0     2  ...   0        0    0         0     0   \n",
       "anthony        0       0     0  ...   0       10    0         0     0   \n",
       "bill           0       0     1  ...   1        0    0         0     0   \n",
       "bo             1       0     0  ...   0        0    0         0     1   \n",
       "dave           0       0     0  ...   0        0    0         0     0   \n",
       "hasan          0       0     1  ...   0        0    2         0     0   \n",
       "jim            0       0     1  ...   0        0    0         0     0   \n",
       "joe            0       0     2  ...   0        0    0         0     0   \n",
       "john           0       0     3  ...   0        0    0         0     0   \n",
       "louis          0       0     1  ...   0        0    0         0     0   \n",
       "mike           0       0     0  ...   0        0    0         2     0   \n",
       "ricky          1       1     2  ...   0        0    0         0     0   \n",
       "\n",
       "         zillion  zombie  zombies  zoo  éclair  \n",
       "ali            0       1        0    0       0  \n",
       "anthony        0       0        0    0       0  \n",
       "bill           1       1        1    0       0  \n",
       "bo             0       0        0    0       0  \n",
       "dave           0       0        0    0       0  \n",
       "hasan          0       0        0    0       0  \n",
       "jim            0       0        0    0       0  \n",
       "joe            0       0        0    0       0  \n",
       "john           0       0        0    0       1  \n",
       "louis          0       0        0    0       0  \n",
       "mike           0       0        0    0       0  \n",
       "ricky          0       0        0    1       0  \n",
       "\n",
       "[12 rows x 5591 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación del nuevo corpus, ahora sólo con sustantivos y adjetivos.  Además eliminamos las stop words con max_df superior a 0.8\n",
    "cvna = CountVectorizer(stop_words=\"english\", max_df=.8)\n",
    "datos_cvna = cvna.fit_transform(datos_sust_adj['transcripcion'])\n",
    "datos_dtmna = pd.DataFrame(datos_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "datos_dtmna.index = datos_sust_adj.index\n",
    "datos_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del corpus gensim\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(datos_dtmna.transpose()))\n",
    "\n",
    "# Diccionario de vocabulario\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"joke\" + 0.005*\"mom\" + 0.004*\"parents\" + 0.003*\"jokes\" + 0.003*\"bo\" + 0.002*\"comedy\" + 0.002*\"hasan\" + 0.002*\"clinton\" + 0.002*\"eye\" + 0.002*\"repeat\"'),\n",
       " (1,\n",
       "  '0.003*\"son\" + 0.003*\"ass\" + 0.003*\"gun\" + 0.003*\"jenny\" + 0.003*\"guns\" + 0.003*\"ahah\" + 0.003*\"class\" + 0.002*\"friend\" + 0.002*\"gay\" + 0.002*\"business\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 2\n",
    "np.random.seed(2)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"ass\" + 0.003*\"gun\" + 0.003*\"jenny\" + 0.003*\"guns\" + 0.003*\"dog\" + 0.003*\"dick\" + 0.003*\"class\" + 0.003*\"morning\" + 0.002*\"girls\" + 0.002*\"sense\"'),\n",
       " (1,\n",
       "  '0.004*\"mom\" + 0.004*\"bo\" + 0.004*\"clinton\" + 0.004*\"repeat\" + 0.004*\"wife\" + 0.004*\"ahah\" + 0.004*\"gay\" + 0.003*\"eye\" + 0.003*\"friend\" + 0.003*\"ok\"'),\n",
       " (2,\n",
       "  '0.009*\"joke\" + 0.005*\"mom\" + 0.005*\"hasan\" + 0.004*\"parents\" + 0.004*\"jokes\" + 0.004*\"anthony\" + 0.003*\"twitter\" + 0.003*\"brown\" + 0.003*\"comedy\" + 0.003*\"mad\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 3\n",
    "np.random.seed(222)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"joke\" + 0.004*\"jenny\" + 0.003*\"nuts\" + 0.003*\"dead\" + 0.003*\"parents\" + 0.003*\"tit\" + 0.003*\"hell\" + 0.003*\"morning\" + 0.003*\"dog\" + 0.002*\"gun\"'),\n",
       " (1,\n",
       "  '0.005*\"mom\" + 0.004*\"bo\" + 0.003*\"clinton\" + 0.003*\"wife\" + 0.003*\"repeat\" + 0.003*\"ahah\" + 0.003*\"gay\" + 0.003*\"friend\" + 0.003*\"eye\" + 0.003*\"dick\"'),\n",
       " (2,\n",
       "  '0.009*\"joke\" + 0.007*\"guns\" + 0.006*\"anthony\" + 0.005*\"gun\" + 0.005*\"ass\" + 0.005*\"party\" + 0.004*\"girlfriend\" + 0.004*\"grandma\" + 0.004*\"jokes\" + 0.004*\"son\"'),\n",
       " (3,\n",
       "  '0.009*\"hasan\" + 0.007*\"mom\" + 0.006*\"parents\" + 0.006*\"brown\" + 0.004*\"bike\" + 0.004*\"birthday\" + 0.004*\"york\" + 0.003*\"door\" + 0.003*\"bethany\" + 0.003*\"pizza\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 4\n",
    "np.random.seed(222)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando los temas de cada documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 10 'topic models' que hemos extraido, el caso que parece tener más sentido (!) es el 4º tema de la prueba con sustantivos y adjetivos.  Afinamos ahora el proceso a través de más iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"joke\" + 0.004*\"jenny\" + 0.003*\"nuts\" + 0.003*\"dead\" + 0.003*\"hell\" + 0.003*\"tit\" + 0.003*\"parents\" + 0.003*\"morning\" + 0.003*\"dog\" + 0.002*\"food\"'),\n",
       " (1,\n",
       "  '0.005*\"mom\" + 0.004*\"bo\" + 0.003*\"clinton\" + 0.003*\"wife\" + 0.003*\"repeat\" + 0.003*\"ahah\" + 0.003*\"gay\" + 0.003*\"eye\" + 0.003*\"friend\" + 0.003*\"dick\"'),\n",
       " (2,\n",
       "  '0.009*\"joke\" + 0.007*\"guns\" + 0.006*\"anthony\" + 0.005*\"gun\" + 0.005*\"ass\" + 0.005*\"party\" + 0.004*\"grandma\" + 0.004*\"girlfriend\" + 0.004*\"jokes\" + 0.004*\"son\"'),\n",
       " (3,\n",
       "  '0.009*\"hasan\" + 0.007*\"mom\" + 0.006*\"parents\" + 0.006*\"brown\" + 0.004*\"bike\" + 0.004*\"birthday\" + 0.004*\"york\" + 0.004*\"door\" + 0.003*\"pizza\" + 0.003*\"bethany\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo LDA final (de momento)\n",
    "np.random.seed(222)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=180)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tocaría etiquetar estos temas.\n",
    "Podría ser:\n",
    "* 0: Bromas\n",
    "* 1: Insultos y religión\n",
    "* 2: Familia\n",
    "* 3: ¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'ali'),\n",
       " (2, 'anthony'),\n",
       " (0, 'bill'),\n",
       " (3, 'bo'),\n",
       " (0, 'dave'),\n",
       " (2, 'hasan'),\n",
       " (2, 'jim'),\n",
       " (1, 'joe'),\n",
       " (2, 'john'),\n",
       " (3, 'louis'),\n",
       " (2, 'mike'),\n",
       " (0, 'ricky')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos los temas que contiene cada transcripción\n",
    "corpus_transformado = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformado], datos_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prueba a modificar los parámetros para obtener unos mejores resultados.\n",
    "2. Crea un nuevo topic model que incluya términos de una parte diferente de la oración (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) y comprueba si se obtienen mejores temas. (Comprobar si analizando otros elementos obtenemos tópicos más representativos):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
